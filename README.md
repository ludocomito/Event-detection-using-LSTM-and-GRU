## Introduction
Event Detection can be considered a particular instance of Sequence Labelling where the task is about identifying and categorizing events in a sequence of text. In this task, an event is considered a specific occurrence involving participants. Long Short-Term Memory (LSTM) and Gated Recur- rent Unit (GRU) are two types of Recurrent Neural Networks (RNNs) that fit well this kind of tasks, given their ability to capture long-term dependencies in sequential data. The work presented in this report describes a series of experiments based on LSTM and GRU architectures, involving hyperparameter tuning and the choice of different ways of representing word vectors using word embedding models.

### Word embeddings and trained models
Word embeddings and pretrained models are public available at the following gdrive links:
- [Download GloVe word vectors](https://drive.google.com/drive/folders/1GQHeRwLjT2akPyTGwxRWBJ5Mk-gwF9_a?usp=share_link)
- [Download trained models](https://drive.google.com/drive/folders/1aqpO2yoMr-FEpCBGd7gsU8qZpcjuYu5x?usp=share_link)
